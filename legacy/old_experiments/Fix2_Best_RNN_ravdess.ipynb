{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fix2 Best RNN ravdess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgWqQkpEhBiv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "1fc97aa1-b6ad-442e-e737-da7c33f9ccc9"
      },
      "source": [
        "%cd drive/'My Drive'/speech\n",
        "%ls\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/speech'\n",
            "/content/drive/My Drive/speech\n",
            "iemocap128-mal.pk  iemocap128.pk  iemocap1.pk  \u001b[0m\u001b[01;34mlogs\u001b[0m/  ravdess-mfccs.pk\n",
            "Fri Jun  5 19:42:59 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUN4qKxrgzFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4a899cb2-1815-4d99-f3b6-c25d015fcd8c"
      },
      "source": [
        "import numpy as np\n",
        "import pickle as pk\n",
        "\n",
        "dataset = ()\n",
        "with open('ravdess-mfccs.pk','rb') as f:\n",
        "  dataset = pk.load(f)\n",
        "x , y = dataset\n",
        "\n",
        "print(x[0].shape)\n",
        "x = [ xi.T for xi in x  ] #in order to padding\n",
        "\n",
        "c = 9\n",
        "\n",
        "frames = 1 + 2*c \n",
        "x_nuevo = []\n",
        "mini = 0\n",
        "for xi in x:\n",
        "  new_xi = []\n",
        "  # print(xi.shape)\n",
        "  for i in range( len(xi) - frames ):\n",
        "    # print ( xi[i:i+frames] )\n",
        "    auch = xi[i:i+frames].flatten()\n",
        "    # print(auch.shape)\n",
        "    new_xi.append(auch)\n",
        "    # break\n",
        "\n",
        "  # print ( np.array(new_xi).shape )\n",
        "  # break\n",
        "  # print ( new_xi  ) \n",
        "  x_nuevo.append(new_xi)\n",
        "\n",
        "print ( len(x_nuevo) )\n",
        "print ( len(x_nuevo[0]) )\n",
        "print ( len(x_nuevo[0][0]) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26, 351)\n",
            "1440\n",
            "332\n",
            "494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6lEfEaHb_xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cfc0617e-fb05-4885-8b6b-eed3f06c19ea"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import keras\n",
        "\n",
        "x_padded = keras.preprocessing.sequence.pad_sequences(x_nuevo, padding='post', value=0)\n",
        "\n",
        "label_encoder = LabelBinarizer()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "print ( x_padded.shape )\n",
        "print ( y_encoded.shape )\n",
        "label_encoder.inverse_transform( y_encoded[0].reshape(1,-1) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(1440, 509, 494)\n",
            "(1440, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['surprised'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58qvsjiqg8fa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e0b287c-1499-4a04-a4db-192e1623858f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Masking,LSTM,Dense,Softmax, Dropout , Bidirectional, Conv1D\n",
        "from keras.backend import maximum, minimum\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_padded , y_encoded , test_size=0.2, random_state=42 )\n",
        "\n",
        "def clip_relu(x):\n",
        "    return minimum( maximum( 0.0, x ) , 20.0 )\n",
        "\n",
        "model = Sequential()\n",
        "model.add(  Masking(mask_value=0) )\n",
        "model.add( Dense (128, activation=clip_relu ) ) # 3   #128 \n",
        "model.add( Dropout(0.15)) \n",
        "model.add( Dense (120, activation=clip_relu) ) # 3 \n",
        "model.add( Dropout(0.15))\n",
        "model.add( Dense (120, activation=clip_relu) ) # 3 \n",
        "model.add( Dropout(0.15)) \n",
        "model.add( Dense (120, activation=clip_relu) ) # 3 \n",
        "model.add( Bidirectional ( LSTM (120, input_shape=(509,120 ) ) )  ) #2048\n",
        "model.add( Dropout(0.15))\n",
        "model.add( Dense (120, activation=\"relu\") ) # 3 \n",
        "model.add( Dropout(0.15)) \n",
        "model.add( Dense (8,activation=\"sigmoid\"  ) )\n",
        "\n",
        "\n",
        "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "model.compile( optimizer=\"adam\" , loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n",
        "history = model.fit(x_train, y_train, batch_size=1200, validation_data=(x_test, y_test) , epochs=400)\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1152 samples, validate on 288 samples\n",
            "Epoch 1/400\n",
            "1152/1152 [==============================] - 7s 6ms/step - loss: 2.0963 - accuracy: 0.1172 - val_loss: 2.0678 - val_accuracy: 0.1528\n",
            "Epoch 2/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0793 - accuracy: 0.1554 - val_loss: 2.0810 - val_accuracy: 0.1389\n",
            "Epoch 3/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0732 - accuracy: 0.1293 - val_loss: 2.0852 - val_accuracy: 0.1042\n",
            "Epoch 4/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0658 - accuracy: 0.1632 - val_loss: 2.0841 - val_accuracy: 0.1042\n",
            "Epoch 5/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0701 - accuracy: 0.1311 - val_loss: 2.0745 - val_accuracy: 0.1076\n",
            "Epoch 6/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0642 - accuracy: 0.1432 - val_loss: 2.0687 - val_accuracy: 0.1042\n",
            "Epoch 7/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0652 - accuracy: 0.1311 - val_loss: 2.0624 - val_accuracy: 0.1007\n",
            "Epoch 8/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0676 - accuracy: 0.1389 - val_loss: 2.0627 - val_accuracy: 0.1111\n",
            "Epoch 9/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0697 - accuracy: 0.1302 - val_loss: 2.0637 - val_accuracy: 0.1076\n",
            "Epoch 10/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0678 - accuracy: 0.1337 - val_loss: 2.0642 - val_accuracy: 0.1146\n",
            "Epoch 11/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0691 - accuracy: 0.1267 - val_loss: 2.0650 - val_accuracy: 0.1146\n",
            "Epoch 12/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0659 - accuracy: 0.1363 - val_loss: 2.0659 - val_accuracy: 0.1076\n",
            "Epoch 13/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0669 - accuracy: 0.1476 - val_loss: 2.0665 - val_accuracy: 0.1076\n",
            "Epoch 14/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0640 - accuracy: 0.1424 - val_loss: 2.0663 - val_accuracy: 0.1076\n",
            "Epoch 15/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0627 - accuracy: 0.1372 - val_loss: 2.0674 - val_accuracy: 0.1076\n",
            "Epoch 16/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0681 - accuracy: 0.1441 - val_loss: 2.0656 - val_accuracy: 0.1042\n",
            "Epoch 17/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0643 - accuracy: 0.1319 - val_loss: 2.0647 - val_accuracy: 0.1042\n",
            "Epoch 18/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0625 - accuracy: 0.1319 - val_loss: 2.0639 - val_accuracy: 0.1042\n",
            "Epoch 19/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0652 - accuracy: 0.1285 - val_loss: 2.0651 - val_accuracy: 0.0938\n",
            "Epoch 20/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0670 - accuracy: 0.1415 - val_loss: 2.0660 - val_accuracy: 0.0972\n",
            "Epoch 21/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0653 - accuracy: 0.1337 - val_loss: 2.0645 - val_accuracy: 0.1181\n",
            "Epoch 22/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0592 - accuracy: 0.1363 - val_loss: 2.0624 - val_accuracy: 0.1285\n",
            "Epoch 23/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0657 - accuracy: 0.1354 - val_loss: 2.0609 - val_accuracy: 0.1111\n",
            "Epoch 24/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0633 - accuracy: 0.1337 - val_loss: 2.0573 - val_accuracy: 0.1285\n",
            "Epoch 25/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0645 - accuracy: 0.1319 - val_loss: 2.0578 - val_accuracy: 0.1111\n",
            "Epoch 26/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0592 - accuracy: 0.1589 - val_loss: 2.0588 - val_accuracy: 0.1076\n",
            "Epoch 27/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0626 - accuracy: 0.1380 - val_loss: 2.0600 - val_accuracy: 0.1215\n",
            "Epoch 28/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0644 - accuracy: 0.1415 - val_loss: 2.0606 - val_accuracy: 0.1250\n",
            "Epoch 29/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0685 - accuracy: 0.1267 - val_loss: 2.0605 - val_accuracy: 0.1285\n",
            "Epoch 30/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0610 - accuracy: 0.1432 - val_loss: 2.0603 - val_accuracy: 0.1424\n",
            "Epoch 31/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0612 - accuracy: 0.1363 - val_loss: 2.0599 - val_accuracy: 0.1458\n",
            "Epoch 32/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0639 - accuracy: 0.1484 - val_loss: 2.0584 - val_accuracy: 0.1597\n",
            "Epoch 33/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0612 - accuracy: 0.1424 - val_loss: 2.0570 - val_accuracy: 0.1458\n",
            "Epoch 34/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0580 - accuracy: 0.1562 - val_loss: 2.0555 - val_accuracy: 0.1389\n",
            "Epoch 35/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0562 - accuracy: 0.1467 - val_loss: 2.0538 - val_accuracy: 0.1701\n",
            "Epoch 36/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0580 - accuracy: 0.1753 - val_loss: 2.0498 - val_accuracy: 0.1736\n",
            "Epoch 37/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0540 - accuracy: 0.1589 - val_loss: 2.0468 - val_accuracy: 0.1562\n",
            "Epoch 38/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0530 - accuracy: 0.1545 - val_loss: 2.0421 - val_accuracy: 0.1701\n",
            "Epoch 39/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0520 - accuracy: 0.1562 - val_loss: 2.0411 - val_accuracy: 0.1771\n",
            "Epoch 40/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0461 - accuracy: 0.1606 - val_loss: 2.0335 - val_accuracy: 0.1771\n",
            "Epoch 41/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0396 - accuracy: 0.1649 - val_loss: 2.0391 - val_accuracy: 0.1493\n",
            "Epoch 42/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0416 - accuracy: 0.1858 - val_loss: 2.0223 - val_accuracy: 0.1632\n",
            "Epoch 43/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0364 - accuracy: 0.1771 - val_loss: 2.0228 - val_accuracy: 0.1632\n",
            "Epoch 44/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0266 - accuracy: 0.1823 - val_loss: 2.0190 - val_accuracy: 0.1701\n",
            "Epoch 45/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0274 - accuracy: 0.1832 - val_loss: 2.0154 - val_accuracy: 0.1736\n",
            "Epoch 46/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0192 - accuracy: 0.1719 - val_loss: 2.0120 - val_accuracy: 0.1944\n",
            "Epoch 47/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0149 - accuracy: 0.1753 - val_loss: 2.0067 - val_accuracy: 0.1701\n",
            "Epoch 48/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0152 - accuracy: 0.1858 - val_loss: 1.9821 - val_accuracy: 0.2014\n",
            "Epoch 49/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9943 - accuracy: 0.1927 - val_loss: 1.9869 - val_accuracy: 0.1806\n",
            "Epoch 50/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9839 - accuracy: 0.2049 - val_loss: 1.9607 - val_accuracy: 0.2153\n",
            "Epoch 51/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9709 - accuracy: 0.2144 - val_loss: 1.9574 - val_accuracy: 0.2014\n",
            "Epoch 52/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9755 - accuracy: 0.1997 - val_loss: 2.0901 - val_accuracy: 0.1319\n",
            "Epoch 53/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 2.0563 - accuracy: 0.1658 - val_loss: 1.9472 - val_accuracy: 0.2153\n",
            "Epoch 54/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9623 - accuracy: 0.2109 - val_loss: 1.9938 - val_accuracy: 0.1840\n",
            "Epoch 55/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 2.0181 - accuracy: 0.1606 - val_loss: 1.9753 - val_accuracy: 0.1806\n",
            "Epoch 56/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9887 - accuracy: 0.1780 - val_loss: 1.9314 - val_accuracy: 0.2083\n",
            "Epoch 57/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9423 - accuracy: 0.2170 - val_loss: 1.9575 - val_accuracy: 0.2014\n",
            "Epoch 58/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9716 - accuracy: 0.1866 - val_loss: 1.9121 - val_accuracy: 0.2049\n",
            "Epoch 59/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9162 - accuracy: 0.2231 - val_loss: 1.9421 - val_accuracy: 0.1910\n",
            "Epoch 60/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9387 - accuracy: 0.2205 - val_loss: 1.9148 - val_accuracy: 0.2083\n",
            "Epoch 61/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9092 - accuracy: 0.2300 - val_loss: 1.9048 - val_accuracy: 0.2257\n",
            "Epoch 62/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9078 - accuracy: 0.2240 - val_loss: 1.8931 - val_accuracy: 0.2188\n",
            "Epoch 63/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8845 - accuracy: 0.2439 - val_loss: 1.8892 - val_accuracy: 0.2118\n",
            "Epoch 64/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8773 - accuracy: 0.2465 - val_loss: 1.8773 - val_accuracy: 0.2326\n",
            "Epoch 65/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.8587 - accuracy: 0.2509 - val_loss: 1.8685 - val_accuracy: 0.2326\n",
            "Epoch 66/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8525 - accuracy: 0.2457 - val_loss: 1.8616 - val_accuracy: 0.2465\n",
            "Epoch 67/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8456 - accuracy: 0.2526 - val_loss: 1.8683 - val_accuracy: 0.2431\n",
            "Epoch 68/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8602 - accuracy: 0.2396 - val_loss: 1.8701 - val_accuracy: 0.2326\n",
            "Epoch 69/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8429 - accuracy: 0.2656 - val_loss: 1.8654 - val_accuracy: 0.2431\n",
            "Epoch 70/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8326 - accuracy: 0.2474 - val_loss: 1.8819 - val_accuracy: 0.2361\n",
            "Epoch 71/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8867 - accuracy: 0.2370 - val_loss: 1.9945 - val_accuracy: 0.2083\n",
            "Epoch 72/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.9250 - accuracy: 0.2361 - val_loss: 1.8828 - val_accuracy: 0.2569\n",
            "Epoch 73/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8799 - accuracy: 0.2526 - val_loss: 1.8798 - val_accuracy: 0.2292\n",
            "Epoch 74/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8745 - accuracy: 0.2526 - val_loss: 1.8736 - val_accuracy: 0.2222\n",
            "Epoch 75/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8747 - accuracy: 0.2474 - val_loss: 1.8660 - val_accuracy: 0.2639\n",
            "Epoch 76/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8565 - accuracy: 0.2622 - val_loss: 1.8733 - val_accuracy: 0.2569\n",
            "Epoch 77/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8735 - accuracy: 0.2465 - val_loss: 1.8541 - val_accuracy: 0.2500\n",
            "Epoch 78/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8419 - accuracy: 0.2682 - val_loss: 1.8512 - val_accuracy: 0.2431\n",
            "Epoch 79/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8430 - accuracy: 0.2708 - val_loss: 1.8689 - val_accuracy: 0.2361\n",
            "Epoch 80/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8700 - accuracy: 0.2465 - val_loss: 1.8388 - val_accuracy: 0.2743\n",
            "Epoch 81/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8172 - accuracy: 0.2760 - val_loss: 1.8617 - val_accuracy: 0.2396\n",
            "Epoch 82/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8377 - accuracy: 0.2734 - val_loss: 1.8476 - val_accuracy: 0.2639\n",
            "Epoch 83/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.8222 - accuracy: 0.2812 - val_loss: 1.8399 - val_accuracy: 0.2535\n",
            "Epoch 84/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8079 - accuracy: 0.2795 - val_loss: 1.8457 - val_accuracy: 0.2396\n",
            "Epoch 85/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8038 - accuracy: 0.2891 - val_loss: 1.8451 - val_accuracy: 0.2361\n",
            "Epoch 86/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.8009 - accuracy: 0.2891 - val_loss: 1.8284 - val_accuracy: 0.2639\n",
            "Epoch 87/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8140 - accuracy: 0.2734 - val_loss: 1.8453 - val_accuracy: 0.2604\n",
            "Epoch 88/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8190 - accuracy: 0.2908 - val_loss: 1.8606 - val_accuracy: 0.2396\n",
            "Epoch 89/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7945 - accuracy: 0.2752 - val_loss: 1.8387 - val_accuracy: 0.2500\n",
            "Epoch 90/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7827 - accuracy: 0.2986 - val_loss: 1.8365 - val_accuracy: 0.2465\n",
            "Epoch 91/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7955 - accuracy: 0.2995 - val_loss: 1.8288 - val_accuracy: 0.2500\n",
            "Epoch 92/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7864 - accuracy: 0.2865 - val_loss: 1.8335 - val_accuracy: 0.2396\n",
            "Epoch 93/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7617 - accuracy: 0.2873 - val_loss: 1.8568 - val_accuracy: 0.2361\n",
            "Epoch 94/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.8031 - accuracy: 0.2743 - val_loss: 1.8133 - val_accuracy: 0.2535\n",
            "Epoch 95/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7696 - accuracy: 0.2995 - val_loss: 1.8604 - val_accuracy: 0.2326\n",
            "Epoch 96/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8364 - accuracy: 0.2856 - val_loss: 1.8220 - val_accuracy: 0.2604\n",
            "Epoch 97/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7651 - accuracy: 0.3247 - val_loss: 1.8396 - val_accuracy: 0.2604\n",
            "Epoch 98/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8126 - accuracy: 0.2769 - val_loss: 1.8253 - val_accuracy: 0.2292\n",
            "Epoch 99/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7768 - accuracy: 0.2908 - val_loss: 1.8357 - val_accuracy: 0.2604\n",
            "Epoch 100/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7749 - accuracy: 0.2865 - val_loss: 1.8451 - val_accuracy: 0.2639\n",
            "Epoch 101/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7904 - accuracy: 0.2934 - val_loss: 1.8200 - val_accuracy: 0.2604\n",
            "Epoch 102/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7451 - accuracy: 0.3012 - val_loss: 1.8127 - val_accuracy: 0.2708\n",
            "Epoch 103/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7714 - accuracy: 0.2951 - val_loss: 1.8054 - val_accuracy: 0.2708\n",
            "Epoch 104/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7714 - accuracy: 0.2934 - val_loss: 1.8051 - val_accuracy: 0.2812\n",
            "Epoch 105/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7532 - accuracy: 0.3116 - val_loss: 1.8066 - val_accuracy: 0.2812\n",
            "Epoch 106/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7463 - accuracy: 0.2951 - val_loss: 1.8036 - val_accuracy: 0.2778\n",
            "Epoch 107/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.7357 - accuracy: 0.3186 - val_loss: 1.8052 - val_accuracy: 0.2778\n",
            "Epoch 108/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7297 - accuracy: 0.3220 - val_loss: 1.8086 - val_accuracy: 0.2604\n",
            "Epoch 109/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7300 - accuracy: 0.3142 - val_loss: 1.8037 - val_accuracy: 0.2674\n",
            "Epoch 110/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7252 - accuracy: 0.3108 - val_loss: 1.7911 - val_accuracy: 0.2639\n",
            "Epoch 111/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7323 - accuracy: 0.3038 - val_loss: 1.7887 - val_accuracy: 0.2639\n",
            "Epoch 112/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7207 - accuracy: 0.3160 - val_loss: 1.7888 - val_accuracy: 0.2604\n",
            "Epoch 113/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7136 - accuracy: 0.3142 - val_loss: 1.7852 - val_accuracy: 0.2743\n",
            "Epoch 114/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7045 - accuracy: 0.3229 - val_loss: 1.7858 - val_accuracy: 0.2743\n",
            "Epoch 115/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7163 - accuracy: 0.3125 - val_loss: 1.7947 - val_accuracy: 0.2674\n",
            "Epoch 116/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7026 - accuracy: 0.3099 - val_loss: 1.7943 - val_accuracy: 0.2743\n",
            "Epoch 117/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6926 - accuracy: 0.3247 - val_loss: 1.7981 - val_accuracy: 0.2778\n",
            "Epoch 118/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6880 - accuracy: 0.3455 - val_loss: 1.8054 - val_accuracy: 0.2743\n",
            "Epoch 119/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6869 - accuracy: 0.3385 - val_loss: 1.8139 - val_accuracy: 0.2812\n",
            "Epoch 120/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7160 - accuracy: 0.3325 - val_loss: 1.7997 - val_accuracy: 0.3160\n",
            "Epoch 121/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7275 - accuracy: 0.3151 - val_loss: 1.8053 - val_accuracy: 0.2778\n",
            "Epoch 122/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6961 - accuracy: 0.3168 - val_loss: 1.8332 - val_accuracy: 0.2743\n",
            "Epoch 123/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7136 - accuracy: 0.3177 - val_loss: 1.8142 - val_accuracy: 0.2708\n",
            "Epoch 124/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6795 - accuracy: 0.3264 - val_loss: 1.8161 - val_accuracy: 0.2743\n",
            "Epoch 125/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6924 - accuracy: 0.3290 - val_loss: 1.8257 - val_accuracy: 0.2674\n",
            "Epoch 126/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6988 - accuracy: 0.3229 - val_loss: 1.7945 - val_accuracy: 0.2847\n",
            "Epoch 127/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6964 - accuracy: 0.3394 - val_loss: 1.7864 - val_accuracy: 0.2917\n",
            "Epoch 128/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6805 - accuracy: 0.3394 - val_loss: 1.7864 - val_accuracy: 0.2812\n",
            "Epoch 129/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6726 - accuracy: 0.3507 - val_loss: 1.8158 - val_accuracy: 0.2569\n",
            "Epoch 130/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7028 - accuracy: 0.3073 - val_loss: 1.7575 - val_accuracy: 0.2951\n",
            "Epoch 131/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6848 - accuracy: 0.3247 - val_loss: 1.7593 - val_accuracy: 0.3056\n",
            "Epoch 132/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6687 - accuracy: 0.3420 - val_loss: 1.7705 - val_accuracy: 0.3021\n",
            "Epoch 133/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6655 - accuracy: 0.3394 - val_loss: 1.7857 - val_accuracy: 0.3125\n",
            "Epoch 134/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6707 - accuracy: 0.3333 - val_loss: 1.8004 - val_accuracy: 0.3090\n",
            "Epoch 135/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6695 - accuracy: 0.3290 - val_loss: 1.7693 - val_accuracy: 0.2847\n",
            "Epoch 136/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6830 - accuracy: 0.3203 - val_loss: 1.7808 - val_accuracy: 0.2743\n",
            "Epoch 137/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6953 - accuracy: 0.3247 - val_loss: 1.7627 - val_accuracy: 0.2847\n",
            "Epoch 138/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6599 - accuracy: 0.3264 - val_loss: 1.7855 - val_accuracy: 0.2812\n",
            "Epoch 139/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6661 - accuracy: 0.3273 - val_loss: 1.7564 - val_accuracy: 0.2951\n",
            "Epoch 140/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6684 - accuracy: 0.3333 - val_loss: 1.7421 - val_accuracy: 0.3090\n",
            "Epoch 141/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6653 - accuracy: 0.3255 - val_loss: 1.7541 - val_accuracy: 0.2917\n",
            "Epoch 142/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6487 - accuracy: 0.3394 - val_loss: 1.7575 - val_accuracy: 0.2917\n",
            "Epoch 143/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6545 - accuracy: 0.3264 - val_loss: 1.7329 - val_accuracy: 0.3160\n",
            "Epoch 144/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6318 - accuracy: 0.3438 - val_loss: 1.7398 - val_accuracy: 0.3125\n",
            "Epoch 145/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6645 - accuracy: 0.3325 - val_loss: 1.7443 - val_accuracy: 0.3160\n",
            "Epoch 146/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6366 - accuracy: 0.3377 - val_loss: 1.7698 - val_accuracy: 0.2847\n",
            "Epoch 147/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6363 - accuracy: 0.3385 - val_loss: 1.7774 - val_accuracy: 0.2917\n",
            "Epoch 148/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6425 - accuracy: 0.3385 - val_loss: 1.8079 - val_accuracy: 0.3021\n",
            "Epoch 149/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7164 - accuracy: 0.3290 - val_loss: 1.8573 - val_accuracy: 0.2639\n",
            "Epoch 150/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7426 - accuracy: 0.3125 - val_loss: 1.7898 - val_accuracy: 0.3229\n",
            "Epoch 151/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6456 - accuracy: 0.3316 - val_loss: 1.8473 - val_accuracy: 0.2778\n",
            "Epoch 152/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.7248 - accuracy: 0.3125 - val_loss: 1.7766 - val_accuracy: 0.2986\n",
            "Epoch 153/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6339 - accuracy: 0.3481 - val_loss: 1.7796 - val_accuracy: 0.2812\n",
            "Epoch 154/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6635 - accuracy: 0.3281 - val_loss: 1.7733 - val_accuracy: 0.2812\n",
            "Epoch 155/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6670 - accuracy: 0.3203 - val_loss: 1.7547 - val_accuracy: 0.3021\n",
            "Epoch 156/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6191 - accuracy: 0.3438 - val_loss: 1.7927 - val_accuracy: 0.2951\n",
            "Epoch 157/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6670 - accuracy: 0.3351 - val_loss: 1.7808 - val_accuracy: 0.2951\n",
            "Epoch 158/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6249 - accuracy: 0.3602 - val_loss: 1.7396 - val_accuracy: 0.2951\n",
            "Epoch 159/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6050 - accuracy: 0.3576 - val_loss: 1.7553 - val_accuracy: 0.2951\n",
            "Epoch 160/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6548 - accuracy: 0.3464 - val_loss: 1.7256 - val_accuracy: 0.2986\n",
            "Epoch 161/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6112 - accuracy: 0.3550 - val_loss: 1.7371 - val_accuracy: 0.2986\n",
            "Epoch 162/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6231 - accuracy: 0.3438 - val_loss: 1.7472 - val_accuracy: 0.2951\n",
            "Epoch 163/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6060 - accuracy: 0.3481 - val_loss: 1.7152 - val_accuracy: 0.3090\n",
            "Epoch 164/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5915 - accuracy: 0.3559 - val_loss: 1.7204 - val_accuracy: 0.3090\n",
            "Epoch 165/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6131 - accuracy: 0.3620 - val_loss: 1.7189 - val_accuracy: 0.3090\n",
            "Epoch 166/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6000 - accuracy: 0.3550 - val_loss: 1.7305 - val_accuracy: 0.3160\n",
            "Epoch 167/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6000 - accuracy: 0.3628 - val_loss: 1.7390 - val_accuracy: 0.3125\n",
            "Epoch 168/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6081 - accuracy: 0.3576 - val_loss: 1.7582 - val_accuracy: 0.3160\n",
            "Epoch 169/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6075 - accuracy: 0.3576 - val_loss: 1.7297 - val_accuracy: 0.3229\n",
            "Epoch 170/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5974 - accuracy: 0.3672 - val_loss: 1.8562 - val_accuracy: 0.2986\n",
            "Epoch 171/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6910 - accuracy: 0.3507 - val_loss: 1.7434 - val_accuracy: 0.3299\n",
            "Epoch 172/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6030 - accuracy: 0.3698 - val_loss: 1.8426 - val_accuracy: 0.3056\n",
            "Epoch 173/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.8059 - accuracy: 0.3186 - val_loss: 1.7309 - val_accuracy: 0.3264\n",
            "Epoch 174/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5890 - accuracy: 0.3663 - val_loss: 1.9235 - val_accuracy: 0.2604\n",
            "Epoch 175/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7522 - accuracy: 0.3142 - val_loss: 1.9257 - val_accuracy: 0.2500\n",
            "Epoch 176/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7762 - accuracy: 0.3038 - val_loss: 1.7450 - val_accuracy: 0.3021\n",
            "Epoch 177/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5979 - accuracy: 0.3681 - val_loss: 1.7395 - val_accuracy: 0.3125\n",
            "Epoch 178/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6567 - accuracy: 0.3637 - val_loss: 1.7595 - val_accuracy: 0.3194\n",
            "Epoch 179/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7281 - accuracy: 0.3273 - val_loss: 1.7382 - val_accuracy: 0.3090\n",
            "Epoch 180/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6429 - accuracy: 0.3464 - val_loss: 1.7464 - val_accuracy: 0.3125\n",
            "Epoch 181/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6360 - accuracy: 0.3490 - val_loss: 1.7967 - val_accuracy: 0.2917\n",
            "Epoch 182/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.6623 - accuracy: 0.3351 - val_loss: 1.7966 - val_accuracy: 0.2917\n",
            "Epoch 183/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6858 - accuracy: 0.3203 - val_loss: 1.7383 - val_accuracy: 0.3090\n",
            "Epoch 184/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6217 - accuracy: 0.3620 - val_loss: 1.7302 - val_accuracy: 0.3229\n",
            "Epoch 185/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6331 - accuracy: 0.3585 - val_loss: 1.8070 - val_accuracy: 0.2951\n",
            "Epoch 186/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.7183 - accuracy: 0.3238 - val_loss: 1.7582 - val_accuracy: 0.3056\n",
            "Epoch 187/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6566 - accuracy: 0.3498 - val_loss: 1.7275 - val_accuracy: 0.2951\n",
            "Epoch 188/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.5999 - accuracy: 0.3759 - val_loss: 1.7550 - val_accuracy: 0.2847\n",
            "Epoch 189/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6263 - accuracy: 0.3464 - val_loss: 1.7815 - val_accuracy: 0.2847\n",
            "Epoch 190/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6402 - accuracy: 0.3411 - val_loss: 1.7543 - val_accuracy: 0.2951\n",
            "Epoch 191/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6031 - accuracy: 0.3759 - val_loss: 1.7392 - val_accuracy: 0.3160\n",
            "Epoch 192/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5985 - accuracy: 0.3568 - val_loss: 1.7374 - val_accuracy: 0.3056\n",
            "Epoch 193/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6133 - accuracy: 0.3498 - val_loss: 1.7304 - val_accuracy: 0.3160\n",
            "Epoch 194/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6224 - accuracy: 0.3490 - val_loss: 1.7354 - val_accuracy: 0.3125\n",
            "Epoch 195/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5804 - accuracy: 0.3663 - val_loss: 1.7363 - val_accuracy: 0.3229\n",
            "Epoch 196/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5740 - accuracy: 0.3837 - val_loss: 1.7497 - val_accuracy: 0.3090\n",
            "Epoch 197/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.6010 - accuracy: 0.3576 - val_loss: 1.7286 - val_accuracy: 0.3229\n",
            "Epoch 198/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5938 - accuracy: 0.3550 - val_loss: 1.6895 - val_accuracy: 0.3264\n",
            "Epoch 199/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5565 - accuracy: 0.3915 - val_loss: 1.7023 - val_accuracy: 0.3472\n",
            "Epoch 200/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5846 - accuracy: 0.3767 - val_loss: 1.6998 - val_accuracy: 0.3368\n",
            "Epoch 201/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5784 - accuracy: 0.3707 - val_loss: 1.7104 - val_accuracy: 0.3333\n",
            "Epoch 202/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5456 - accuracy: 0.3993 - val_loss: 1.7458 - val_accuracy: 0.3194\n",
            "Epoch 203/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5820 - accuracy: 0.3681 - val_loss: 1.7095 - val_accuracy: 0.3264\n",
            "Epoch 204/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.5469 - accuracy: 0.3750 - val_loss: 1.7087 - val_accuracy: 0.3264\n",
            "Epoch 205/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5519 - accuracy: 0.3759 - val_loss: 1.7140 - val_accuracy: 0.3229\n",
            "Epoch 206/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5489 - accuracy: 0.3932 - val_loss: 1.6948 - val_accuracy: 0.3403\n",
            "Epoch 207/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5260 - accuracy: 0.4028 - val_loss: 1.6915 - val_accuracy: 0.3368\n",
            "Epoch 208/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5383 - accuracy: 0.3767 - val_loss: 1.6925 - val_accuracy: 0.3507\n",
            "Epoch 209/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5309 - accuracy: 0.3819 - val_loss: 1.6868 - val_accuracy: 0.3403\n",
            "Epoch 210/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5317 - accuracy: 0.3906 - val_loss: 1.6892 - val_accuracy: 0.3472\n",
            "Epoch 211/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5180 - accuracy: 0.3941 - val_loss: 1.6790 - val_accuracy: 0.3368\n",
            "Epoch 212/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5166 - accuracy: 0.4019 - val_loss: 1.7026 - val_accuracy: 0.3229\n",
            "Epoch 213/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.5397 - accuracy: 0.3759 - val_loss: 1.6965 - val_accuracy: 0.3403\n",
            "Epoch 214/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5175 - accuracy: 0.4028 - val_loss: 1.6834 - val_accuracy: 0.3576\n",
            "Epoch 215/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5191 - accuracy: 0.4089 - val_loss: 1.6890 - val_accuracy: 0.3854\n",
            "Epoch 216/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.5160 - accuracy: 0.3958 - val_loss: 1.6585 - val_accuracy: 0.3646\n",
            "Epoch 217/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5117 - accuracy: 0.4054 - val_loss: 1.6757 - val_accuracy: 0.3542\n",
            "Epoch 218/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4952 - accuracy: 0.4201 - val_loss: 1.6888 - val_accuracy: 0.3715\n",
            "Epoch 219/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.5078 - accuracy: 0.3993 - val_loss: 1.6857 - val_accuracy: 0.3611\n",
            "Epoch 220/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4986 - accuracy: 0.4115 - val_loss: 1.6604 - val_accuracy: 0.3785\n",
            "Epoch 221/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4773 - accuracy: 0.4158 - val_loss: 1.6555 - val_accuracy: 0.3819\n",
            "Epoch 222/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4933 - accuracy: 0.4262 - val_loss: 1.6584 - val_accuracy: 0.3750\n",
            "Epoch 223/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4664 - accuracy: 0.4306 - val_loss: 1.6708 - val_accuracy: 0.3924\n",
            "Epoch 224/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4633 - accuracy: 0.4384 - val_loss: 1.6877 - val_accuracy: 0.3576\n",
            "Epoch 225/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4765 - accuracy: 0.4332 - val_loss: 1.6652 - val_accuracy: 0.3646\n",
            "Epoch 226/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4780 - accuracy: 0.4245 - val_loss: 1.6389 - val_accuracy: 0.3958\n",
            "Epoch 227/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4590 - accuracy: 0.4366 - val_loss: 1.6270 - val_accuracy: 0.3993\n",
            "Epoch 228/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4834 - accuracy: 0.4227 - val_loss: 1.6333 - val_accuracy: 0.3958\n",
            "Epoch 229/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4572 - accuracy: 0.4227 - val_loss: 1.6570 - val_accuracy: 0.3819\n",
            "Epoch 230/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4636 - accuracy: 0.4288 - val_loss: 1.6761 - val_accuracy: 0.3785\n",
            "Epoch 231/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4908 - accuracy: 0.4141 - val_loss: 1.6540 - val_accuracy: 0.3958\n",
            "Epoch 232/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4616 - accuracy: 0.4453 - val_loss: 1.6394 - val_accuracy: 0.4028\n",
            "Epoch 233/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4287 - accuracy: 0.4635 - val_loss: 1.6320 - val_accuracy: 0.3889\n",
            "Epoch 234/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4704 - accuracy: 0.4306 - val_loss: 1.6462 - val_accuracy: 0.3889\n",
            "Epoch 235/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4426 - accuracy: 0.4470 - val_loss: 1.6824 - val_accuracy: 0.3681\n",
            "Epoch 236/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4595 - accuracy: 0.4332 - val_loss: 1.6721 - val_accuracy: 0.3819\n",
            "Epoch 237/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4278 - accuracy: 0.4453 - val_loss: 1.6100 - val_accuracy: 0.3993\n",
            "Epoch 238/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4204 - accuracy: 0.4557 - val_loss: 1.5880 - val_accuracy: 0.4028\n",
            "Epoch 239/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4535 - accuracy: 0.4497 - val_loss: 1.5957 - val_accuracy: 0.4132\n",
            "Epoch 240/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4517 - accuracy: 0.4523 - val_loss: 1.6507 - val_accuracy: 0.3924\n",
            "Epoch 241/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4374 - accuracy: 0.4349 - val_loss: 1.6443 - val_accuracy: 0.4028\n",
            "Epoch 242/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4367 - accuracy: 0.4523 - val_loss: 1.5830 - val_accuracy: 0.4097\n",
            "Epoch 243/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4393 - accuracy: 0.4557 - val_loss: 1.5534 - val_accuracy: 0.4028\n",
            "Epoch 244/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4331 - accuracy: 0.4609 - val_loss: 1.5844 - val_accuracy: 0.4132\n",
            "Epoch 245/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4269 - accuracy: 0.4514 - val_loss: 1.6200 - val_accuracy: 0.3993\n",
            "Epoch 246/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4222 - accuracy: 0.4644 - val_loss: 1.5717 - val_accuracy: 0.4271\n",
            "Epoch 247/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3818 - accuracy: 0.4731 - val_loss: 1.5348 - val_accuracy: 0.4444\n",
            "Epoch 248/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.4159 - accuracy: 0.4714 - val_loss: 1.5155 - val_accuracy: 0.4653\n",
            "Epoch 249/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3913 - accuracy: 0.4757 - val_loss: 1.5288 - val_accuracy: 0.4340\n",
            "Epoch 250/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.3960 - accuracy: 0.4757 - val_loss: 1.5660 - val_accuracy: 0.3924\n",
            "Epoch 251/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4081 - accuracy: 0.4766 - val_loss: 1.5563 - val_accuracy: 0.3924\n",
            "Epoch 252/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4159 - accuracy: 0.4566 - val_loss: 1.5185 - val_accuracy: 0.4236\n",
            "Epoch 253/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3755 - accuracy: 0.4766 - val_loss: 1.5387 - val_accuracy: 0.4410\n",
            "Epoch 254/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.4037 - accuracy: 0.4540 - val_loss: 1.5516 - val_accuracy: 0.4340\n",
            "Epoch 255/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.3725 - accuracy: 0.4757 - val_loss: 1.5501 - val_accuracy: 0.4062\n",
            "Epoch 256/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3439 - accuracy: 0.4861 - val_loss: 1.5620 - val_accuracy: 0.3958\n",
            "Epoch 257/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3659 - accuracy: 0.4705 - val_loss: 1.5457 - val_accuracy: 0.4132\n",
            "Epoch 258/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3648 - accuracy: 0.4861 - val_loss: 1.5239 - val_accuracy: 0.4132\n",
            "Epoch 259/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3294 - accuracy: 0.4983 - val_loss: 1.4768 - val_accuracy: 0.4410\n",
            "Epoch 260/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3505 - accuracy: 0.4844 - val_loss: 1.4824 - val_accuracy: 0.4375\n",
            "Epoch 261/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3245 - accuracy: 0.4974 - val_loss: 1.5069 - val_accuracy: 0.4097\n",
            "Epoch 262/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3199 - accuracy: 0.5087 - val_loss: 1.5367 - val_accuracy: 0.3924\n",
            "Epoch 263/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.3609 - accuracy: 0.4913 - val_loss: 1.5099 - val_accuracy: 0.4097\n",
            "Epoch 264/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3112 - accuracy: 0.5043 - val_loss: 1.4699 - val_accuracy: 0.4514\n",
            "Epoch 265/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.3303 - accuracy: 0.4974 - val_loss: 1.5241 - val_accuracy: 0.4306\n",
            "Epoch 266/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2658 - accuracy: 0.5278 - val_loss: 1.5403 - val_accuracy: 0.4306\n",
            "Epoch 267/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2968 - accuracy: 0.5191 - val_loss: 1.4652 - val_accuracy: 0.4653\n",
            "Epoch 268/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2628 - accuracy: 0.5252 - val_loss: 1.4260 - val_accuracy: 0.4896\n",
            "Epoch 269/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2873 - accuracy: 0.5043 - val_loss: 1.4296 - val_accuracy: 0.4722\n",
            "Epoch 270/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2699 - accuracy: 0.5304 - val_loss: 1.4339 - val_accuracy: 0.4688\n",
            "Epoch 271/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2502 - accuracy: 0.5321 - val_loss: 1.4667 - val_accuracy: 0.4410\n",
            "Epoch 272/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2451 - accuracy: 0.5043 - val_loss: 1.4472 - val_accuracy: 0.4514\n",
            "Epoch 273/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2678 - accuracy: 0.5260 - val_loss: 1.4506 - val_accuracy: 0.4618\n",
            "Epoch 274/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2896 - accuracy: 0.5191 - val_loss: 1.4230 - val_accuracy: 0.4479\n",
            "Epoch 275/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2246 - accuracy: 0.5521 - val_loss: 1.4612 - val_accuracy: 0.4479\n",
            "Epoch 276/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2515 - accuracy: 0.5252 - val_loss: 1.4931 - val_accuracy: 0.4583\n",
            "Epoch 277/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2616 - accuracy: 0.5295 - val_loss: 1.4946 - val_accuracy: 0.4618\n",
            "Epoch 278/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2494 - accuracy: 0.5182 - val_loss: 1.5452 - val_accuracy: 0.4375\n",
            "Epoch 279/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2597 - accuracy: 0.5139 - val_loss: 1.4269 - val_accuracy: 0.4861\n",
            "Epoch 280/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2685 - accuracy: 0.5156 - val_loss: 1.4270 - val_accuracy: 0.4757\n",
            "Epoch 281/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2153 - accuracy: 0.5425 - val_loss: 1.5653 - val_accuracy: 0.4132\n",
            "Epoch 282/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2463 - accuracy: 0.5417 - val_loss: 1.5474 - val_accuracy: 0.4444\n",
            "Epoch 283/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2239 - accuracy: 0.5330 - val_loss: 1.3846 - val_accuracy: 0.5035\n",
            "Epoch 284/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2085 - accuracy: 0.5408 - val_loss: 1.3698 - val_accuracy: 0.5035\n",
            "Epoch 285/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2056 - accuracy: 0.5503 - val_loss: 1.4522 - val_accuracy: 0.4688\n",
            "Epoch 286/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2158 - accuracy: 0.5252 - val_loss: 1.4432 - val_accuracy: 0.4792\n",
            "Epoch 287/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2094 - accuracy: 0.5538 - val_loss: 1.4104 - val_accuracy: 0.4965\n",
            "Epoch 288/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2678 - accuracy: 0.5069 - val_loss: 1.4193 - val_accuracy: 0.4931\n",
            "Epoch 289/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2888 - accuracy: 0.4974 - val_loss: 1.4338 - val_accuracy: 0.4410\n",
            "Epoch 290/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2611 - accuracy: 0.5321 - val_loss: 1.5414 - val_accuracy: 0.3924\n",
            "Epoch 291/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.3470 - accuracy: 0.4835 - val_loss: 1.5018 - val_accuracy: 0.4167\n",
            "Epoch 292/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2424 - accuracy: 0.5260 - val_loss: 1.4250 - val_accuracy: 0.4722\n",
            "Epoch 293/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1943 - accuracy: 0.5486 - val_loss: 1.4681 - val_accuracy: 0.4757\n",
            "Epoch 294/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2807 - accuracy: 0.5087 - val_loss: 1.4647 - val_accuracy: 0.4583\n",
            "Epoch 295/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2348 - accuracy: 0.5278 - val_loss: 1.5526 - val_accuracy: 0.4132\n",
            "Epoch 296/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2202 - accuracy: 0.5503 - val_loss: 1.5403 - val_accuracy: 0.4271\n",
            "Epoch 297/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.2628 - accuracy: 0.5191 - val_loss: 1.4320 - val_accuracy: 0.4514\n",
            "Epoch 298/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2226 - accuracy: 0.5408 - val_loss: 1.3617 - val_accuracy: 0.5069\n",
            "Epoch 299/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.1976 - accuracy: 0.5486 - val_loss: 1.4197 - val_accuracy: 0.5069\n",
            "Epoch 300/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1811 - accuracy: 0.5582 - val_loss: 1.4496 - val_accuracy: 0.4896\n",
            "Epoch 301/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1699 - accuracy: 0.5660 - val_loss: 1.4914 - val_accuracy: 0.4861\n",
            "Epoch 302/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1973 - accuracy: 0.5634 - val_loss: 1.4542 - val_accuracy: 0.4861\n",
            "Epoch 303/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1707 - accuracy: 0.5773 - val_loss: 1.3973 - val_accuracy: 0.4931\n",
            "Epoch 304/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.2106 - accuracy: 0.5599 - val_loss: 1.3725 - val_accuracy: 0.5208\n",
            "Epoch 305/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.1443 - accuracy: 0.5894 - val_loss: 1.4128 - val_accuracy: 0.4931\n",
            "Epoch 306/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1657 - accuracy: 0.5634 - val_loss: 1.3652 - val_accuracy: 0.5035\n",
            "Epoch 307/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1805 - accuracy: 0.5391 - val_loss: 1.3858 - val_accuracy: 0.5000\n",
            "Epoch 308/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.1142 - accuracy: 0.5755 - val_loss: 1.3948 - val_accuracy: 0.5000\n",
            "Epoch 309/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1251 - accuracy: 0.5885 - val_loss: 1.3668 - val_accuracy: 0.5243\n",
            "Epoch 310/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0871 - accuracy: 0.5859 - val_loss: 1.4483 - val_accuracy: 0.4931\n",
            "Epoch 311/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1724 - accuracy: 0.5642 - val_loss: 1.3864 - val_accuracy: 0.5278\n",
            "Epoch 312/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.1211 - accuracy: 0.5773 - val_loss: 1.4276 - val_accuracy: 0.5035\n",
            "Epoch 313/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0495 - accuracy: 0.6102 - val_loss: 1.4008 - val_accuracy: 0.5208\n",
            "Epoch 314/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.0741 - accuracy: 0.5903 - val_loss: 1.3744 - val_accuracy: 0.5243\n",
            "Epoch 315/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.0715 - accuracy: 0.6137 - val_loss: 1.4219 - val_accuracy: 0.5104\n",
            "Epoch 316/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0809 - accuracy: 0.5903 - val_loss: 1.3792 - val_accuracy: 0.5000\n",
            "Epoch 317/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0200 - accuracy: 0.6085 - val_loss: 1.3945 - val_accuracy: 0.4965\n",
            "Epoch 318/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0653 - accuracy: 0.6033 - val_loss: 1.3860 - val_accuracy: 0.5000\n",
            "Epoch 319/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0223 - accuracy: 0.6102 - val_loss: 1.4042 - val_accuracy: 0.4861\n",
            "Epoch 320/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0219 - accuracy: 0.6172 - val_loss: 1.3537 - val_accuracy: 0.5139\n",
            "Epoch 321/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 1.0114 - accuracy: 0.6155 - val_loss: 1.4080 - val_accuracy: 0.5000\n",
            "Epoch 322/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0218 - accuracy: 0.6050 - val_loss: 1.3778 - val_accuracy: 0.5035\n",
            "Epoch 323/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9818 - accuracy: 0.6319 - val_loss: 1.3327 - val_accuracy: 0.5382\n",
            "Epoch 324/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9841 - accuracy: 0.6267 - val_loss: 1.3114 - val_accuracy: 0.5521\n",
            "Epoch 325/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 1.0029 - accuracy: 0.6363 - val_loss: 1.3546 - val_accuracy: 0.5382\n",
            "Epoch 326/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9893 - accuracy: 0.6372 - val_loss: 1.3947 - val_accuracy: 0.5208\n",
            "Epoch 327/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9979 - accuracy: 0.6259 - val_loss: 1.3692 - val_accuracy: 0.5486\n",
            "Epoch 328/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9961 - accuracy: 0.6155 - val_loss: 1.3671 - val_accuracy: 0.5382\n",
            "Epoch 329/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9915 - accuracy: 0.6224 - val_loss: 1.3783 - val_accuracy: 0.5382\n",
            "Epoch 330/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9951 - accuracy: 0.6432 - val_loss: 1.3642 - val_accuracy: 0.5139\n",
            "Epoch 331/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9858 - accuracy: 0.6259 - val_loss: 1.3508 - val_accuracy: 0.5347\n",
            "Epoch 332/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9718 - accuracy: 0.6328 - val_loss: 1.3144 - val_accuracy: 0.5451\n",
            "Epoch 333/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9630 - accuracy: 0.6406 - val_loss: 1.3405 - val_accuracy: 0.5278\n",
            "Epoch 334/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9608 - accuracy: 0.6450 - val_loss: 1.3791 - val_accuracy: 0.5069\n",
            "Epoch 335/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9536 - accuracy: 0.6380 - val_loss: 1.3074 - val_accuracy: 0.5382\n",
            "Epoch 336/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9137 - accuracy: 0.6589 - val_loss: 1.2872 - val_accuracy: 0.5347\n",
            "Epoch 337/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9177 - accuracy: 0.6476 - val_loss: 1.3499 - val_accuracy: 0.5243\n",
            "Epoch 338/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9291 - accuracy: 0.6606 - val_loss: 1.4014 - val_accuracy: 0.5069\n",
            "Epoch 339/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9143 - accuracy: 0.6589 - val_loss: 1.3321 - val_accuracy: 0.5312\n",
            "Epoch 340/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9466 - accuracy: 0.6432 - val_loss: 1.3455 - val_accuracy: 0.5486\n",
            "Epoch 341/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9469 - accuracy: 0.6450 - val_loss: 1.3323 - val_accuracy: 0.5278\n",
            "Epoch 342/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8922 - accuracy: 0.6536 - val_loss: 1.3599 - val_accuracy: 0.5382\n",
            "Epoch 343/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8836 - accuracy: 0.6693 - val_loss: 1.3794 - val_accuracy: 0.5312\n",
            "Epoch 344/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9222 - accuracy: 0.6424 - val_loss: 1.3567 - val_accuracy: 0.5417\n",
            "Epoch 345/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9130 - accuracy: 0.6580 - val_loss: 1.3673 - val_accuracy: 0.5486\n",
            "Epoch 346/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8781 - accuracy: 0.6771 - val_loss: 1.3673 - val_accuracy: 0.5382\n",
            "Epoch 347/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8751 - accuracy: 0.6693 - val_loss: 1.3240 - val_accuracy: 0.5278\n",
            "Epoch 348/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8901 - accuracy: 0.6641 - val_loss: 1.4137 - val_accuracy: 0.5347\n",
            "Epoch 349/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8397 - accuracy: 0.6892 - val_loss: 1.3979 - val_accuracy: 0.5382\n",
            "Epoch 350/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8364 - accuracy: 0.6944 - val_loss: 1.3668 - val_accuracy: 0.5347\n",
            "Epoch 351/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8698 - accuracy: 0.6623 - val_loss: 1.3754 - val_accuracy: 0.5312\n",
            "Epoch 352/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8212 - accuracy: 0.7031 - val_loss: 1.4052 - val_accuracy: 0.5243\n",
            "Epoch 353/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8393 - accuracy: 0.7057 - val_loss: 1.3345 - val_accuracy: 0.5035\n",
            "Epoch 354/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8445 - accuracy: 0.6762 - val_loss: 1.3873 - val_accuracy: 0.5278\n",
            "Epoch 355/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.9188 - accuracy: 0.6467 - val_loss: 1.5521 - val_accuracy: 0.4896\n",
            "Epoch 356/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.9908 - accuracy: 0.6372 - val_loss: 1.3981 - val_accuracy: 0.5208\n",
            "Epoch 357/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8461 - accuracy: 0.6875 - val_loss: 1.2754 - val_accuracy: 0.5347\n",
            "Epoch 358/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8874 - accuracy: 0.6753 - val_loss: 1.3414 - val_accuracy: 0.5312\n",
            "Epoch 359/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8332 - accuracy: 0.6962 - val_loss: 1.4234 - val_accuracy: 0.5278\n",
            "Epoch 360/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8767 - accuracy: 0.6753 - val_loss: 1.3788 - val_accuracy: 0.5451\n",
            "Epoch 361/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.8528 - accuracy: 0.6771 - val_loss: 1.2158 - val_accuracy: 0.5868\n",
            "Epoch 362/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8344 - accuracy: 0.7092 - val_loss: 1.2939 - val_accuracy: 0.5590\n",
            "Epoch 363/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.8556 - accuracy: 0.6701 - val_loss: 1.3661 - val_accuracy: 0.5382\n",
            "Epoch 364/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7809 - accuracy: 0.7066 - val_loss: 1.3502 - val_accuracy: 0.5451\n",
            "Epoch 365/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7973 - accuracy: 0.6988 - val_loss: 1.2607 - val_accuracy: 0.5903\n",
            "Epoch 366/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7832 - accuracy: 0.7188 - val_loss: 1.3135 - val_accuracy: 0.5694\n",
            "Epoch 367/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.7445 - accuracy: 0.7326 - val_loss: 1.3163 - val_accuracy: 0.5417\n",
            "Epoch 368/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.7441 - accuracy: 0.7135 - val_loss: 1.3927 - val_accuracy: 0.5347\n",
            "Epoch 369/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7746 - accuracy: 0.7057 - val_loss: 1.3460 - val_accuracy: 0.5486\n",
            "Epoch 370/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.7419 - accuracy: 0.7326 - val_loss: 1.2585 - val_accuracy: 0.5556\n",
            "Epoch 371/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7113 - accuracy: 0.7266 - val_loss: 1.3352 - val_accuracy: 0.5799\n",
            "Epoch 372/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7428 - accuracy: 0.7214 - val_loss: 1.2724 - val_accuracy: 0.5556\n",
            "Epoch 373/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7239 - accuracy: 0.7326 - val_loss: 1.3368 - val_accuracy: 0.5382\n",
            "Epoch 374/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7177 - accuracy: 0.7300 - val_loss: 1.2476 - val_accuracy: 0.5521\n",
            "Epoch 375/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6925 - accuracy: 0.7448 - val_loss: 1.3728 - val_accuracy: 0.5243\n",
            "Epoch 376/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7148 - accuracy: 0.7405 - val_loss: 1.2855 - val_accuracy: 0.5556\n",
            "Epoch 377/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6894 - accuracy: 0.7439 - val_loss: 1.2850 - val_accuracy: 0.5625\n",
            "Epoch 378/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6777 - accuracy: 0.7491 - val_loss: 1.3075 - val_accuracy: 0.5868\n",
            "Epoch 379/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6636 - accuracy: 0.7587 - val_loss: 1.2668 - val_accuracy: 0.5625\n",
            "Epoch 380/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6475 - accuracy: 0.7682 - val_loss: 1.3109 - val_accuracy: 0.5556\n",
            "Epoch 381/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7074 - accuracy: 0.7387 - val_loss: 1.3970 - val_accuracy: 0.5660\n",
            "Epoch 382/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6595 - accuracy: 0.7595 - val_loss: 1.2884 - val_accuracy: 0.5729\n",
            "Epoch 383/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6376 - accuracy: 0.7691 - val_loss: 1.2883 - val_accuracy: 0.5556\n",
            "Epoch 384/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6312 - accuracy: 0.7535 - val_loss: 1.3905 - val_accuracy: 0.5938\n",
            "Epoch 385/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6534 - accuracy: 0.7517 - val_loss: 1.2547 - val_accuracy: 0.5903\n",
            "Epoch 386/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6388 - accuracy: 0.7569 - val_loss: 1.3173 - val_accuracy: 0.5972\n",
            "Epoch 387/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6664 - accuracy: 0.7604 - val_loss: 1.3089 - val_accuracy: 0.5799\n",
            "Epoch 388/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5955 - accuracy: 0.7899 - val_loss: 1.3229 - val_accuracy: 0.5799\n",
            "Epoch 389/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5760 - accuracy: 0.7951 - val_loss: 1.2290 - val_accuracy: 0.5833\n",
            "Epoch 390/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5990 - accuracy: 0.7769 - val_loss: 1.2964 - val_accuracy: 0.5694\n",
            "Epoch 391/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5934 - accuracy: 0.7908 - val_loss: 1.3121 - val_accuracy: 0.5799\n",
            "Epoch 392/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5645 - accuracy: 0.7865 - val_loss: 1.3425 - val_accuracy: 0.5833\n",
            "Epoch 393/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6172 - accuracy: 0.7769 - val_loss: 1.2931 - val_accuracy: 0.5729\n",
            "Epoch 394/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5589 - accuracy: 0.8003 - val_loss: 1.3707 - val_accuracy: 0.5764\n",
            "Epoch 395/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5437 - accuracy: 0.8021 - val_loss: 1.3590 - val_accuracy: 0.5590\n",
            "Epoch 396/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5601 - accuracy: 0.7995 - val_loss: 1.2964 - val_accuracy: 0.5799\n",
            "Epoch 397/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5696 - accuracy: 0.7934 - val_loss: 1.3503 - val_accuracy: 0.5729\n",
            "Epoch 398/400\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5932 - accuracy: 0.7899 - val_loss: 1.3537 - val_accuracy: 0.5486\n",
            "Epoch 399/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5913 - accuracy: 0.7943 - val_loss: 1.3957 - val_accuracy: 0.5660\n",
            "Epoch 400/400\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5873 - accuracy: 0.7865 - val_loss: 1.3564 - val_accuracy: 0.5764\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking_2 (Masking)          (None, 509, 494)          0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 509, 128)          63360     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 509, 128)          0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 509, 120)          15480     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 509, 120)          0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 509, 120)          14520     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 509, 120)          0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 509, 120)          14520     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 240)               231360    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 240)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 120)               28920     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8)                 968       \n",
            "=================================================================\n",
            "Total params: 369,128\n",
            "Trainable params: 369,128\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyWk_e9thKTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "fa4db7ae-6bee-4e42-a211-82bc581da7c7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxjooLdOWiKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e172057-edee-4fdf-93e1-b1c937e47b75"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=1200, validation_data=(x_test, y_test) , epochs=150)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1152 samples, validate on 288 samples\n",
            "Epoch 1/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5573 - accuracy: 0.8047 - val_loss: 1.2588 - val_accuracy: 0.5799\n",
            "Epoch 2/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5825 - accuracy: 0.7882 - val_loss: 1.4864 - val_accuracy: 0.5625\n",
            "Epoch 3/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.7885 - accuracy: 0.7109 - val_loss: 1.3532 - val_accuracy: 0.5486\n",
            "Epoch 4/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5760 - accuracy: 0.7865 - val_loss: 1.3746 - val_accuracy: 0.5521\n",
            "Epoch 5/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5981 - accuracy: 0.7908 - val_loss: 1.3451 - val_accuracy: 0.5764\n",
            "Epoch 6/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6571 - accuracy: 0.7578 - val_loss: 1.2009 - val_accuracy: 0.5764\n",
            "Epoch 7/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6324 - accuracy: 0.7769 - val_loss: 1.2584 - val_accuracy: 0.5833\n",
            "Epoch 8/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6900 - accuracy: 0.7552 - val_loss: 1.3119 - val_accuracy: 0.5972\n",
            "Epoch 9/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5862 - accuracy: 0.7804 - val_loss: 1.2587 - val_accuracy: 0.5799\n",
            "Epoch 10/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6233 - accuracy: 0.7656 - val_loss: 1.2679 - val_accuracy: 0.6076\n",
            "Epoch 11/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5389 - accuracy: 0.7977 - val_loss: 1.3705 - val_accuracy: 0.5903\n",
            "Epoch 12/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6463 - accuracy: 0.7595 - val_loss: 1.2847 - val_accuracy: 0.6181\n",
            "Epoch 13/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5343 - accuracy: 0.8168 - val_loss: 1.3180 - val_accuracy: 0.5833\n",
            "Epoch 14/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6635 - accuracy: 0.7595 - val_loss: 1.4960 - val_accuracy: 0.5833\n",
            "Epoch 15/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.6063 - accuracy: 0.7682 - val_loss: 1.3209 - val_accuracy: 0.5938\n",
            "Epoch 16/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5154 - accuracy: 0.8142 - val_loss: 1.3055 - val_accuracy: 0.5938\n",
            "Epoch 17/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.6338 - accuracy: 0.7743 - val_loss: 1.4945 - val_accuracy: 0.5590\n",
            "Epoch 18/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5755 - accuracy: 0.7934 - val_loss: 1.4572 - val_accuracy: 0.5278\n",
            "Epoch 19/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5502 - accuracy: 0.8064 - val_loss: 1.3933 - val_accuracy: 0.5521\n",
            "Epoch 20/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5197 - accuracy: 0.8203 - val_loss: 1.3112 - val_accuracy: 0.5833\n",
            "Epoch 21/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5221 - accuracy: 0.8090 - val_loss: 1.3792 - val_accuracy: 0.5972\n",
            "Epoch 22/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.5198 - accuracy: 0.8142 - val_loss: 1.3230 - val_accuracy: 0.5833\n",
            "Epoch 23/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4679 - accuracy: 0.8394 - val_loss: 1.3510 - val_accuracy: 0.5660\n",
            "Epoch 24/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5000 - accuracy: 0.8212 - val_loss: 1.4568 - val_accuracy: 0.5625\n",
            "Epoch 25/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.5131 - accuracy: 0.8116 - val_loss: 1.3391 - val_accuracy: 0.5833\n",
            "Epoch 26/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4351 - accuracy: 0.8446 - val_loss: 1.3013 - val_accuracy: 0.5972\n",
            "Epoch 27/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4602 - accuracy: 0.8403 - val_loss: 1.3439 - val_accuracy: 0.5799\n",
            "Epoch 28/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4284 - accuracy: 0.8559 - val_loss: 1.3240 - val_accuracy: 0.5972\n",
            "Epoch 29/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3808 - accuracy: 0.8698 - val_loss: 1.3072 - val_accuracy: 0.5833\n",
            "Epoch 30/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4209 - accuracy: 0.8550 - val_loss: 1.3634 - val_accuracy: 0.5903\n",
            "Epoch 31/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3888 - accuracy: 0.8637 - val_loss: 1.3389 - val_accuracy: 0.6007\n",
            "Epoch 32/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4113 - accuracy: 0.8507 - val_loss: 1.2966 - val_accuracy: 0.6007\n",
            "Epoch 33/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4083 - accuracy: 0.8602 - val_loss: 1.3007 - val_accuracy: 0.5938\n",
            "Epoch 34/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4164 - accuracy: 0.8481 - val_loss: 1.4012 - val_accuracy: 0.5938\n",
            "Epoch 35/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4404 - accuracy: 0.8394 - val_loss: 1.3425 - val_accuracy: 0.5868\n",
            "Epoch 36/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3707 - accuracy: 0.8750 - val_loss: 1.3125 - val_accuracy: 0.5868\n",
            "Epoch 37/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3874 - accuracy: 0.8741 - val_loss: 1.3639 - val_accuracy: 0.5764\n",
            "Epoch 38/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3875 - accuracy: 0.8550 - val_loss: 1.5473 - val_accuracy: 0.5799\n",
            "Epoch 39/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4127 - accuracy: 0.8628 - val_loss: 1.3812 - val_accuracy: 0.5868\n",
            "Epoch 40/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3584 - accuracy: 0.8741 - val_loss: 1.4019 - val_accuracy: 0.5590\n",
            "Epoch 41/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3737 - accuracy: 0.8698 - val_loss: 1.4666 - val_accuracy: 0.5556\n",
            "Epoch 42/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3411 - accuracy: 0.8819 - val_loss: 1.5231 - val_accuracy: 0.5590\n",
            "Epoch 43/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3742 - accuracy: 0.8733 - val_loss: 1.4145 - val_accuracy: 0.5764\n",
            "Epoch 44/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3358 - accuracy: 0.8906 - val_loss: 1.4116 - val_accuracy: 0.5729\n",
            "Epoch 45/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3436 - accuracy: 0.8750 - val_loss: 1.3496 - val_accuracy: 0.6076\n",
            "Epoch 46/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3700 - accuracy: 0.8646 - val_loss: 1.3830 - val_accuracy: 0.5972\n",
            "Epoch 47/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3752 - accuracy: 0.8628 - val_loss: 1.4599 - val_accuracy: 0.5799\n",
            "Epoch 48/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3972 - accuracy: 0.8646 - val_loss: 1.3617 - val_accuracy: 0.5903\n",
            "Epoch 49/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4708 - accuracy: 0.8464 - val_loss: 1.4502 - val_accuracy: 0.5868\n",
            "Epoch 50/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3384 - accuracy: 0.8793 - val_loss: 1.5916 - val_accuracy: 0.5729\n",
            "Epoch 51/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4048 - accuracy: 0.8438 - val_loss: 1.3883 - val_accuracy: 0.5833\n",
            "Epoch 52/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4343 - accuracy: 0.8420 - val_loss: 1.4022 - val_accuracy: 0.5938\n",
            "Epoch 53/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3601 - accuracy: 0.8750 - val_loss: 1.5177 - val_accuracy: 0.5590\n",
            "Epoch 54/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4148 - accuracy: 0.8394 - val_loss: 1.4027 - val_accuracy: 0.5729\n",
            "Epoch 55/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3434 - accuracy: 0.8733 - val_loss: 1.4563 - val_accuracy: 0.5556\n",
            "Epoch 56/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4511 - accuracy: 0.8403 - val_loss: 1.4331 - val_accuracy: 0.5556\n",
            "Epoch 57/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3815 - accuracy: 0.8707 - val_loss: 1.5333 - val_accuracy: 0.5382\n",
            "Epoch 58/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.4614 - accuracy: 0.8325 - val_loss: 1.4424 - val_accuracy: 0.5833\n",
            "Epoch 59/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3487 - accuracy: 0.8811 - val_loss: 1.4692 - val_accuracy: 0.5868\n",
            "Epoch 60/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4915 - accuracy: 0.8273 - val_loss: 1.4321 - val_accuracy: 0.6111\n",
            "Epoch 61/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3399 - accuracy: 0.8802 - val_loss: 1.5304 - val_accuracy: 0.6007\n",
            "Epoch 62/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.4299 - accuracy: 0.8464 - val_loss: 1.3998 - val_accuracy: 0.6111\n",
            "Epoch 63/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3521 - accuracy: 0.8715 - val_loss: 1.4061 - val_accuracy: 0.6007\n",
            "Epoch 64/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3438 - accuracy: 0.8880 - val_loss: 1.4759 - val_accuracy: 0.5799\n",
            "Epoch 65/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3603 - accuracy: 0.8733 - val_loss: 1.5412 - val_accuracy: 0.5556\n",
            "Epoch 66/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3373 - accuracy: 0.8741 - val_loss: 1.5487 - val_accuracy: 0.5903\n",
            "Epoch 67/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3341 - accuracy: 0.8863 - val_loss: 1.5205 - val_accuracy: 0.5938\n",
            "Epoch 68/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3417 - accuracy: 0.8872 - val_loss: 1.4857 - val_accuracy: 0.6007\n",
            "Epoch 69/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3334 - accuracy: 0.8828 - val_loss: 1.4740 - val_accuracy: 0.6076\n",
            "Epoch 70/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3313 - accuracy: 0.8854 - val_loss: 1.4858 - val_accuracy: 0.6076\n",
            "Epoch 71/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2872 - accuracy: 0.8993 - val_loss: 1.5464 - val_accuracy: 0.6215\n",
            "Epoch 72/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.3020 - accuracy: 0.8854 - val_loss: 1.4579 - val_accuracy: 0.5625\n",
            "Epoch 73/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3173 - accuracy: 0.8880 - val_loss: 1.4413 - val_accuracy: 0.5938\n",
            "Epoch 74/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3001 - accuracy: 0.8898 - val_loss: 1.4671 - val_accuracy: 0.6042\n",
            "Epoch 75/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2778 - accuracy: 0.9002 - val_loss: 1.5066 - val_accuracy: 0.5938\n",
            "Epoch 76/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2980 - accuracy: 0.8967 - val_loss: 1.4654 - val_accuracy: 0.5903\n",
            "Epoch 77/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2504 - accuracy: 0.9271 - val_loss: 1.5000 - val_accuracy: 0.5972\n",
            "Epoch 78/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2483 - accuracy: 0.9149 - val_loss: 1.4579 - val_accuracy: 0.6215\n",
            "Epoch 79/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2463 - accuracy: 0.9071 - val_loss: 1.3968 - val_accuracy: 0.6458\n",
            "Epoch 80/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2769 - accuracy: 0.9045 - val_loss: 1.3988 - val_accuracy: 0.6076\n",
            "Epoch 81/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2953 - accuracy: 0.8984 - val_loss: 1.5496 - val_accuracy: 0.5833\n",
            "Epoch 82/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.3093 - accuracy: 0.8932 - val_loss: 1.4664 - val_accuracy: 0.5938\n",
            "Epoch 83/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2421 - accuracy: 0.9123 - val_loss: 1.4777 - val_accuracy: 0.6076\n",
            "Epoch 84/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2425 - accuracy: 0.9158 - val_loss: 1.4835 - val_accuracy: 0.6146\n",
            "Epoch 85/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2564 - accuracy: 0.9227 - val_loss: 1.5096 - val_accuracy: 0.6076\n",
            "Epoch 86/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2657 - accuracy: 0.9115 - val_loss: 1.5319 - val_accuracy: 0.5938\n",
            "Epoch 87/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2617 - accuracy: 0.9115 - val_loss: 1.5499 - val_accuracy: 0.5868\n",
            "Epoch 88/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2246 - accuracy: 0.9175 - val_loss: 1.5475 - val_accuracy: 0.5903\n",
            "Epoch 89/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2466 - accuracy: 0.9227 - val_loss: 1.5269 - val_accuracy: 0.6042\n",
            "Epoch 90/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2463 - accuracy: 0.9149 - val_loss: 1.5147 - val_accuracy: 0.6007\n",
            "Epoch 91/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2523 - accuracy: 0.9106 - val_loss: 1.5775 - val_accuracy: 0.5833\n",
            "Epoch 92/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2270 - accuracy: 0.9184 - val_loss: 1.6623 - val_accuracy: 0.5833\n",
            "Epoch 93/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2327 - accuracy: 0.9227 - val_loss: 1.6301 - val_accuracy: 0.5938\n",
            "Epoch 94/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2262 - accuracy: 0.9245 - val_loss: 1.5617 - val_accuracy: 0.5903\n",
            "Epoch 95/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2675 - accuracy: 0.9054 - val_loss: 1.5626 - val_accuracy: 0.6146\n",
            "Epoch 96/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2227 - accuracy: 0.9210 - val_loss: 1.6218 - val_accuracy: 0.6285\n",
            "Epoch 97/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2264 - accuracy: 0.9236 - val_loss: 1.5292 - val_accuracy: 0.6146\n",
            "Epoch 98/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2024 - accuracy: 0.9280 - val_loss: 1.5131 - val_accuracy: 0.6007\n",
            "Epoch 99/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2843 - accuracy: 0.9036 - val_loss: 1.7044 - val_accuracy: 0.6042\n",
            "Epoch 100/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2653 - accuracy: 0.9080 - val_loss: 1.6260 - val_accuracy: 0.5938\n",
            "Epoch 101/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1858 - accuracy: 0.9392 - val_loss: 1.5501 - val_accuracy: 0.6111\n",
            "Epoch 102/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2724 - accuracy: 0.9028 - val_loss: 1.5893 - val_accuracy: 0.5972\n",
            "Epoch 103/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2303 - accuracy: 0.9219 - val_loss: 1.7095 - val_accuracy: 0.5903\n",
            "Epoch 104/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2552 - accuracy: 0.9158 - val_loss: 1.5326 - val_accuracy: 0.5938\n",
            "Epoch 105/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2359 - accuracy: 0.9141 - val_loss: 1.4996 - val_accuracy: 0.5903\n",
            "Epoch 106/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2781 - accuracy: 0.9141 - val_loss: 1.5793 - val_accuracy: 0.6111\n",
            "Epoch 107/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2032 - accuracy: 0.9358 - val_loss: 1.6177 - val_accuracy: 0.6146\n",
            "Epoch 108/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2271 - accuracy: 0.9288 - val_loss: 1.5640 - val_accuracy: 0.6354\n",
            "Epoch 109/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1915 - accuracy: 0.9358 - val_loss: 1.5263 - val_accuracy: 0.6007\n",
            "Epoch 110/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1941 - accuracy: 0.9306 - val_loss: 1.6189 - val_accuracy: 0.5903\n",
            "Epoch 111/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2278 - accuracy: 0.9167 - val_loss: 1.6364 - val_accuracy: 0.6076\n",
            "Epoch 112/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1766 - accuracy: 0.9401 - val_loss: 1.5633 - val_accuracy: 0.6181\n",
            "Epoch 113/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2046 - accuracy: 0.9288 - val_loss: 1.5374 - val_accuracy: 0.6181\n",
            "Epoch 114/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2009 - accuracy: 0.9323 - val_loss: 1.6536 - val_accuracy: 0.5972\n",
            "Epoch 115/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1946 - accuracy: 0.9280 - val_loss: 1.6447 - val_accuracy: 0.6042\n",
            "Epoch 116/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1744 - accuracy: 0.9444 - val_loss: 1.5429 - val_accuracy: 0.6076\n",
            "Epoch 117/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2014 - accuracy: 0.9358 - val_loss: 1.6533 - val_accuracy: 0.6042\n",
            "Epoch 118/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1725 - accuracy: 0.9392 - val_loss: 1.7157 - val_accuracy: 0.5938\n",
            "Epoch 119/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2385 - accuracy: 0.9227 - val_loss: 1.5257 - val_accuracy: 0.6250\n",
            "Epoch 120/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1958 - accuracy: 0.9332 - val_loss: 1.5673 - val_accuracy: 0.6389\n",
            "Epoch 121/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1981 - accuracy: 0.9280 - val_loss: 1.6236 - val_accuracy: 0.6076\n",
            "Epoch 122/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.2008 - accuracy: 0.9306 - val_loss: 1.6273 - val_accuracy: 0.6146\n",
            "Epoch 123/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1867 - accuracy: 0.9366 - val_loss: 1.5918 - val_accuracy: 0.5972\n",
            "Epoch 124/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2308 - accuracy: 0.9193 - val_loss: 1.5514 - val_accuracy: 0.6181\n",
            "Epoch 125/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1782 - accuracy: 0.9410 - val_loss: 1.6926 - val_accuracy: 0.6076\n",
            "Epoch 126/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1931 - accuracy: 0.9366 - val_loss: 1.6943 - val_accuracy: 0.6111\n",
            "Epoch 127/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1988 - accuracy: 0.9297 - val_loss: 1.5253 - val_accuracy: 0.6285\n",
            "Epoch 128/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1962 - accuracy: 0.9193 - val_loss: 1.6361 - val_accuracy: 0.6181\n",
            "Epoch 129/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1626 - accuracy: 0.9427 - val_loss: 1.6273 - val_accuracy: 0.6076\n",
            "Epoch 130/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1801 - accuracy: 0.9366 - val_loss: 1.5760 - val_accuracy: 0.6319\n",
            "Epoch 131/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1592 - accuracy: 0.9444 - val_loss: 1.5303 - val_accuracy: 0.6424\n",
            "Epoch 132/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2325 - accuracy: 0.9184 - val_loss: 1.6860 - val_accuracy: 0.5938\n",
            "Epoch 133/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2104 - accuracy: 0.9280 - val_loss: 1.6147 - val_accuracy: 0.6076\n",
            "Epoch 134/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1891 - accuracy: 0.9366 - val_loss: 1.5513 - val_accuracy: 0.6250\n",
            "Epoch 135/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.2055 - accuracy: 0.9236 - val_loss: 1.5684 - val_accuracy: 0.5868\n",
            "Epoch 136/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1760 - accuracy: 0.9436 - val_loss: 1.6571 - val_accuracy: 0.6007\n",
            "Epoch 137/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1806 - accuracy: 0.9375 - val_loss: 1.5573 - val_accuracy: 0.6250\n",
            "Epoch 138/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1316 - accuracy: 0.9575 - val_loss: 1.5224 - val_accuracy: 0.6146\n",
            "Epoch 139/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1872 - accuracy: 0.9384 - val_loss: 1.5554 - val_accuracy: 0.6597\n",
            "Epoch 140/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1549 - accuracy: 0.9462 - val_loss: 1.6552 - val_accuracy: 0.6354\n",
            "Epoch 141/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1529 - accuracy: 0.9505 - val_loss: 1.5994 - val_accuracy: 0.6354\n",
            "Epoch 142/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1288 - accuracy: 0.9609 - val_loss: 1.5888 - val_accuracy: 0.6354\n",
            "Epoch 143/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1463 - accuracy: 0.9505 - val_loss: 1.6035 - val_accuracy: 0.6319\n",
            "Epoch 144/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1548 - accuracy: 0.9453 - val_loss: 1.6659 - val_accuracy: 0.6250\n",
            "Epoch 145/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1425 - accuracy: 0.9444 - val_loss: 1.6575 - val_accuracy: 0.6181\n",
            "Epoch 146/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1270 - accuracy: 0.9531 - val_loss: 1.6381 - val_accuracy: 0.6215\n",
            "Epoch 147/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1433 - accuracy: 0.9497 - val_loss: 1.5466 - val_accuracy: 0.6424\n",
            "Epoch 148/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1333 - accuracy: 0.9592 - val_loss: 1.6041 - val_accuracy: 0.6493\n",
            "Epoch 149/150\n",
            "1152/1152 [==============================] - 5s 4ms/step - loss: 0.1157 - accuracy: 0.9635 - val_loss: 1.6036 - val_accuracy: 0.6424\n",
            "Epoch 150/150\n",
            "1152/1152 [==============================] - 5s 5ms/step - loss: 0.1187 - accuracy: 0.9661 - val_loss: 1.5713 - val_accuracy: 0.6493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_kT-tf5WHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aa362e9-71eb-484c-a9eb-4514e1df92cf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "batch_x = np.linspace(1, 60, num=60).reshape( 6 ,  5 , 2  )\n",
        "# batch_size = tf.shape(input=batch_x)[0]\n",
        "batch_x = tf.convert_to_tensor(batch_x, dtype=tf.float32)\n",
        "print (batch_x)\n",
        "batch_size = 6\n",
        "n_context = 1\n",
        "window_width = 2 *n_context  + 1\n",
        "num_channels = 2\n",
        "\n",
        "eye_filter = tf.constant(np.eye(window_width * num_channels)\n",
        "                               .reshape(window_width, num_channels, window_width * num_channels), tf.float32) # pylint: disable=bad-continuation\n",
        "# print ( \"Filtro COnv\" , eye_filter   )\n",
        "\n",
        "batch_x = tf.nn.conv1d(input=batch_x, filters=eye_filter, stride=1, padding='SAME')\n",
        "\n",
        "print ( batch_x)\n",
        "\n",
        "# print (\" :............ :\")\n",
        "batch_x = tf.reshape(batch_x, [batch_size, -1, window_width, num_channels])\n",
        "\n",
        "print ( \"output  \\n\",batch_x)\n",
        "\n",
        "\n",
        "batch_x = tf.transpose(a=batch_x, perm=[1, 0, 2, 3])\n",
        "\n",
        "batch_x = tf.reshape(batch_x, [-1, num_channels + 2*num_channels*n_context])\n",
        "print ( \"pre \\n\",batch_x )\n",
        "\n",
        "pesos = tf.constant (  np.eye( 6 ) ,tf.float32 )\n",
        "# print ( batch_x.shape ) \n",
        "# print ( pesos.shape )\n",
        "out = tf.matmul( batch_x , pesos )\n",
        "print ( out )\n",
        "tf.reshape(out, [-1, batch_size, 6 ])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 1.  2.]\n",
            "  [ 3.  4.]\n",
            "  [ 5.  6.]\n",
            "  [ 7.  8.]\n",
            "  [ 9. 10.]]\n",
            "\n",
            " [[11. 12.]\n",
            "  [13. 14.]\n",
            "  [15. 16.]\n",
            "  [17. 18.]\n",
            "  [19. 20.]]\n",
            "\n",
            " [[21. 22.]\n",
            "  [23. 24.]\n",
            "  [25. 26.]\n",
            "  [27. 28.]\n",
            "  [29. 30.]]\n",
            "\n",
            " [[31. 32.]\n",
            "  [33. 34.]\n",
            "  [35. 36.]\n",
            "  [37. 38.]\n",
            "  [39. 40.]]\n",
            "\n",
            " [[41. 42.]\n",
            "  [43. 44.]\n",
            "  [45. 46.]\n",
            "  [47. 48.]\n",
            "  [49. 50.]]\n",
            "\n",
            " [[51. 52.]\n",
            "  [53. 54.]\n",
            "  [55. 56.]\n",
            "  [57. 58.]\n",
            "  [59. 60.]]], shape=(6, 5, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[[ 0.  0.  1.  2.  3.  4.]\n",
            "  [ 1.  2.  3.  4.  5.  6.]\n",
            "  [ 3.  4.  5.  6.  7.  8.]\n",
            "  [ 5.  6.  7.  8.  9. 10.]\n",
            "  [ 7.  8.  9. 10.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. 11. 12. 13. 14.]\n",
            "  [11. 12. 13. 14. 15. 16.]\n",
            "  [13. 14. 15. 16. 17. 18.]\n",
            "  [15. 16. 17. 18. 19. 20.]\n",
            "  [17. 18. 19. 20.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. 21. 22. 23. 24.]\n",
            "  [21. 22. 23. 24. 25. 26.]\n",
            "  [23. 24. 25. 26. 27. 28.]\n",
            "  [25. 26. 27. 28. 29. 30.]\n",
            "  [27. 28. 29. 30.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. 31. 32. 33. 34.]\n",
            "  [31. 32. 33. 34. 35. 36.]\n",
            "  [33. 34. 35. 36. 37. 38.]\n",
            "  [35. 36. 37. 38. 39. 40.]\n",
            "  [37. 38. 39. 40.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. 41. 42. 43. 44.]\n",
            "  [41. 42. 43. 44. 45. 46.]\n",
            "  [43. 44. 45. 46. 47. 48.]\n",
            "  [45. 46. 47. 48. 49. 50.]\n",
            "  [47. 48. 49. 50.  0.  0.]]\n",
            "\n",
            " [[ 0.  0. 51. 52. 53. 54.]\n",
            "  [51. 52. 53. 54. 55. 56.]\n",
            "  [53. 54. 55. 56. 57. 58.]\n",
            "  [55. 56. 57. 58. 59. 60.]\n",
            "  [57. 58. 59. 60.  0.  0.]]], shape=(6, 5, 6), dtype=float32)\n",
            "output  \n",
            " tf.Tensor(\n",
            "[[[[ 0.  0.]\n",
            "   [ 1.  2.]\n",
            "   [ 3.  4.]]\n",
            "\n",
            "  [[ 1.  2.]\n",
            "   [ 3.  4.]\n",
            "   [ 5.  6.]]\n",
            "\n",
            "  [[ 3.  4.]\n",
            "   [ 5.  6.]\n",
            "   [ 7.  8.]]\n",
            "\n",
            "  [[ 5.  6.]\n",
            "   [ 7.  8.]\n",
            "   [ 9. 10.]]\n",
            "\n",
            "  [[ 7.  8.]\n",
            "   [ 9. 10.]\n",
            "   [ 0.  0.]]]\n",
            "\n",
            "\n",
            " [[[ 0.  0.]\n",
            "   [11. 12.]\n",
            "   [13. 14.]]\n",
            "\n",
            "  [[11. 12.]\n",
            "   [13. 14.]\n",
            "   [15. 16.]]\n",
            "\n",
            "  [[13. 14.]\n",
            "   [15. 16.]\n",
            "   [17. 18.]]\n",
            "\n",
            "  [[15. 16.]\n",
            "   [17. 18.]\n",
            "   [19. 20.]]\n",
            "\n",
            "  [[17. 18.]\n",
            "   [19. 20.]\n",
            "   [ 0.  0.]]]\n",
            "\n",
            "\n",
            " [[[ 0.  0.]\n",
            "   [21. 22.]\n",
            "   [23. 24.]]\n",
            "\n",
            "  [[21. 22.]\n",
            "   [23. 24.]\n",
            "   [25. 26.]]\n",
            "\n",
            "  [[23. 24.]\n",
            "   [25. 26.]\n",
            "   [27. 28.]]\n",
            "\n",
            "  [[25. 26.]\n",
            "   [27. 28.]\n",
            "   [29. 30.]]\n",
            "\n",
            "  [[27. 28.]\n",
            "   [29. 30.]\n",
            "   [ 0.  0.]]]\n",
            "\n",
            "\n",
            " [[[ 0.  0.]\n",
            "   [31. 32.]\n",
            "   [33. 34.]]\n",
            "\n",
            "  [[31. 32.]\n",
            "   [33. 34.]\n",
            "   [35. 36.]]\n",
            "\n",
            "  [[33. 34.]\n",
            "   [35. 36.]\n",
            "   [37. 38.]]\n",
            "\n",
            "  [[35. 36.]\n",
            "   [37. 38.]\n",
            "   [39. 40.]]\n",
            "\n",
            "  [[37. 38.]\n",
            "   [39. 40.]\n",
            "   [ 0.  0.]]]\n",
            "\n",
            "\n",
            " [[[ 0.  0.]\n",
            "   [41. 42.]\n",
            "   [43. 44.]]\n",
            "\n",
            "  [[41. 42.]\n",
            "   [43. 44.]\n",
            "   [45. 46.]]\n",
            "\n",
            "  [[43. 44.]\n",
            "   [45. 46.]\n",
            "   [47. 48.]]\n",
            "\n",
            "  [[45. 46.]\n",
            "   [47. 48.]\n",
            "   [49. 50.]]\n",
            "\n",
            "  [[47. 48.]\n",
            "   [49. 50.]\n",
            "   [ 0.  0.]]]\n",
            "\n",
            "\n",
            " [[[ 0.  0.]\n",
            "   [51. 52.]\n",
            "   [53. 54.]]\n",
            "\n",
            "  [[51. 52.]\n",
            "   [53. 54.]\n",
            "   [55. 56.]]\n",
            "\n",
            "  [[53. 54.]\n",
            "   [55. 56.]\n",
            "   [57. 58.]]\n",
            "\n",
            "  [[55. 56.]\n",
            "   [57. 58.]\n",
            "   [59. 60.]]\n",
            "\n",
            "  [[57. 58.]\n",
            "   [59. 60.]\n",
            "   [ 0.  0.]]]], shape=(6, 5, 3, 2), dtype=float32)\n",
            "pre \n",
            " tf.Tensor(\n",
            "[[ 0.  0.  1.  2.  3.  4.]\n",
            " [ 0.  0. 11. 12. 13. 14.]\n",
            " [ 0.  0. 21. 22. 23. 24.]\n",
            " [ 0.  0. 31. 32. 33. 34.]\n",
            " [ 0.  0. 41. 42. 43. 44.]\n",
            " [ 0.  0. 51. 52. 53. 54.]\n",
            " [ 1.  2.  3.  4.  5.  6.]\n",
            " [11. 12. 13. 14. 15. 16.]\n",
            " [21. 22. 23. 24. 25. 26.]\n",
            " [31. 32. 33. 34. 35. 36.]\n",
            " [41. 42. 43. 44. 45. 46.]\n",
            " [51. 52. 53. 54. 55. 56.]\n",
            " [ 3.  4.  5.  6.  7.  8.]\n",
            " [13. 14. 15. 16. 17. 18.]\n",
            " [23. 24. 25. 26. 27. 28.]\n",
            " [33. 34. 35. 36. 37. 38.]\n",
            " [43. 44. 45. 46. 47. 48.]\n",
            " [53. 54. 55. 56. 57. 58.]\n",
            " [ 5.  6.  7.  8.  9. 10.]\n",
            " [15. 16. 17. 18. 19. 20.]\n",
            " [25. 26. 27. 28. 29. 30.]\n",
            " [35. 36. 37. 38. 39. 40.]\n",
            " [45. 46. 47. 48. 49. 50.]\n",
            " [55. 56. 57. 58. 59. 60.]\n",
            " [ 7.  8.  9. 10.  0.  0.]\n",
            " [17. 18. 19. 20.  0.  0.]\n",
            " [27. 28. 29. 30.  0.  0.]\n",
            " [37. 38. 39. 40.  0.  0.]\n",
            " [47. 48. 49. 50.  0.  0.]\n",
            " [57. 58. 59. 60.  0.  0.]], shape=(30, 6), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.  0.  1.  2.  3.  4.]\n",
            " [ 0.  0. 11. 12. 13. 14.]\n",
            " [ 0.  0. 21. 22. 23. 24.]\n",
            " [ 0.  0. 31. 32. 33. 34.]\n",
            " [ 0.  0. 41. 42. 43. 44.]\n",
            " [ 0.  0. 51. 52. 53. 54.]\n",
            " [ 1.  2.  3.  4.  5.  6.]\n",
            " [11. 12. 13. 14. 15. 16.]\n",
            " [21. 22. 23. 24. 25. 26.]\n",
            " [31. 32. 33. 34. 35. 36.]\n",
            " [41. 42. 43. 44. 45. 46.]\n",
            " [51. 52. 53. 54. 55. 56.]\n",
            " [ 3.  4.  5.  6.  7.  8.]\n",
            " [13. 14. 15. 16. 17. 18.]\n",
            " [23. 24. 25. 26. 27. 28.]\n",
            " [33. 34. 35. 36. 37. 38.]\n",
            " [43. 44. 45. 46. 47. 48.]\n",
            " [53. 54. 55. 56. 57. 58.]\n",
            " [ 5.  6.  7.  8.  9. 10.]\n",
            " [15. 16. 17. 18. 19. 20.]\n",
            " [25. 26. 27. 28. 29. 30.]\n",
            " [35. 36. 37. 38. 39. 40.]\n",
            " [45. 46. 47. 48. 49. 50.]\n",
            " [55. 56. 57. 58. 59. 60.]\n",
            " [ 7.  8.  9. 10.  0.  0.]\n",
            " [17. 18. 19. 20.  0.  0.]\n",
            " [27. 28. 29. 30.  0.  0.]\n",
            " [37. 38. 39. 40.  0.  0.]\n",
            " [47. 48. 49. 50.  0.  0.]\n",
            " [57. 58. 59. 60.  0.  0.]], shape=(30, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 6, 6), dtype=float32, numpy=\n",
              "array([[[ 0.,  0.,  1.,  2.,  3.,  4.],\n",
              "        [ 0.,  0., 11., 12., 13., 14.],\n",
              "        [ 0.,  0., 21., 22., 23., 24.],\n",
              "        [ 0.,  0., 31., 32., 33., 34.],\n",
              "        [ 0.,  0., 41., 42., 43., 44.],\n",
              "        [ 0.,  0., 51., 52., 53., 54.]],\n",
              "\n",
              "       [[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
              "        [11., 12., 13., 14., 15., 16.],\n",
              "        [21., 22., 23., 24., 25., 26.],\n",
              "        [31., 32., 33., 34., 35., 36.],\n",
              "        [41., 42., 43., 44., 45., 46.],\n",
              "        [51., 52., 53., 54., 55., 56.]],\n",
              "\n",
              "       [[ 3.,  4.,  5.,  6.,  7.,  8.],\n",
              "        [13., 14., 15., 16., 17., 18.],\n",
              "        [23., 24., 25., 26., 27., 28.],\n",
              "        [33., 34., 35., 36., 37., 38.],\n",
              "        [43., 44., 45., 46., 47., 48.],\n",
              "        [53., 54., 55., 56., 57., 58.]],\n",
              "\n",
              "       [[ 5.,  6.,  7.,  8.,  9., 10.],\n",
              "        [15., 16., 17., 18., 19., 20.],\n",
              "        [25., 26., 27., 28., 29., 30.],\n",
              "        [35., 36., 37., 38., 39., 40.],\n",
              "        [45., 46., 47., 48., 49., 50.],\n",
              "        [55., 56., 57., 58., 59., 60.]],\n",
              "\n",
              "       [[ 7.,  8.,  9., 10.,  0.,  0.],\n",
              "        [17., 18., 19., 20.,  0.,  0.],\n",
              "        [27., 28., 29., 30.,  0.,  0.],\n",
              "        [37., 38., 39., 40.,  0.,  0.],\n",
              "        [47., 48., 49., 50.,  0.,  0.],\n",
              "        [57., 58., 59., 60.,  0.,  0.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}